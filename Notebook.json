{"paragraphs":[{"text":"%md\n# Combining data from multiple locations\nIn this tutorial, we'll demonstrate how you can use Oracle Big Data Manager Notebook to work with **data stored in multiple locations** such as the edges.csv file on `hdfs` and the USERS Oracle database table. \n\n## About the data\n_Disclaimer: This dataset is completely artificial. It has been generated programatically based on some arbitrary input_\n\nThe `USERS` table contains records about each studen's' name, id, and class category. A value of class_0 in the 'category' column indicates that the student is attending class 0 whereas a value of class_1 indicates that the sudent is attending class 1.  \n\nThe `edges.csv` file contains many rows (records). Each row contains two columns. Each column represents a student id. The two student ids represent two students who are collaborating on a specific class project. \n\nWe use the `USERS` Oracle database table to lookup the names of the student ids and which classes they attended: class_0 or class_1. \n\nWe'll use this dataset to get an idea how frequent such cross-class collaborations are. \n\n\n## Required Action\nIn this tutorial, you will add two new paragraphs to beginning of this note. The two paragraphs will add the following DataFrames into spark-context:\n* `graphText` - DataFrame pointing to the CSV file with graph edges (stored on HDFS)\n* `jdbcDF` - DataFrame pointing to the table containing info about individual students (the USERS table in Oracle database)\n\nThese DataFrames will be processed by the remaining paragraphs in this Note.","user":"anonymous","onBehalfOf":"bigdatamgr","dateUpdated":"2018-05-14T15:35:39+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1526312118107_-1459649496","id":"20180309-125713_248006170","dateCreated":"2018-05-14T15:35:18+0000","dateStarted":"2018-05-14T15:35:39+0000","dateFinished":"2018-05-14T15:35:40+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4155"},{"title":"Process the Data","text":"import org.apache.spark.sql.functions.col\n/* \n * Class representing a graph edge - a connection between two users. \n * Each record in the CSV file corresponds to an instance of this class.\n */\ncase class Edge(\n    idStart: Integer,\n    idEnd: Integer\n)\n\n/* Parse the CSV file into a DataFrame consisting of instances of the Edge class */\nval edges = graphText\n    .map(s => s.split(\",\"))\n    .filter(s => s.size == 2)\n    .filter(s => s(0) != \"ID\")\n    .map(s => Edge(\n            s(0).toInt,\n            s(1).toInt\n        )\n    )\n    .toDF()\n    .as(\"edges\")\n/* Count the number of student projects (e.g. number of edges in the graph) */\nval edgeCount = edges.count()\n\n/* Assign the loaded Oracle database table the alias 'users' for convenience when referencing it's columns. */\nval users = jdbcDF.as(\"users\")\n\n/* Merge the two DataFrames based on user ids. */\nvar friendsDF = edges\n    .join(\n        users, \n        col(\"users.ID\") === col(\"edges.idStart\"), \n        \"inner\"\n    )\n    .select(col(\"users.ID\"), col(\"users.NAME\"), col(\"users.CATEGORY\"), col(\"edges.idEnd\").as(\"friend\"))\n    .as(\"merged\")\n    .join(\n        users, \n        col(\"merged.friend\") === col(\"users.ID\"), \n        \"inner\"\n    )\n    .select(\n        col(\"merged.ID\"), col(\"merged.NAME\"), col(\"merged.CATEGORY\"), \n        col(\"users.ID\").as(\"friend_id\"), col(\"users.NAME\").as(\"friend_name\"), col(\"users.CATEGORY\").as(\"friend_category\")\n    )\n    .as(\"friends\")\nfriendsDF.persist()\nfriendsDF.registerTempTable(\"FRIENDS\")\n\nval intraClassEdgeCount = friendsDF.where(\"CATEGORY = friend_category\").count()\nval interClassEdgeCount = friendsDF.where(\"CATEGORY != friend_category\").count()","dateUpdated":"2018-05-14T15:35:18+0000","config":{"lineNumbers":true,"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":6,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1526312118107_-1459649496","id":"20180309-120737_1290905369","dateCreated":"2018-05-14T15:35:18+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4156"},{"title":"Project Collaboration Details","text":"%sql\nselect * from FRIENDS \nwhere \n    CATEGORY = \"${CATEGORY=,0(class_0)|1(class_1)}\"","dateUpdated":"2018-05-14T15:35:18+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false},"colWidth":6,"editorMode":"ace/mode/sql","runOnSelectionChange":true,"title":true,"results":{"0":{"graph":{"mode":"table","height":156,"optionOpen":false}}},"enabled":true},"settings":{"params":{"class 0|class 1,class 0|class 1":"","class_0|class_1,class_0|class_1":"","fields":["1"],"category":"1","CATEGORY":"1"},"forms":{"CATEGORY":{"name":"CATEGORY","defaultValue":"","options":[{"value":"0","displayName":"class_0","$$hashKey":"object:4354"},{"value":"1","displayName":"class_1","$$hashKey":"object:4355"}],"hidden":false,"$$hashKey":"object:4346"}}},"apps":[],"jobName":"paragraph_1526312118107_-1459649496","id":"20180303-105408_426315715","dateCreated":"2018-05-14T15:35:18+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4157"},{"title":"Project Collaboration Statistics","text":"{\n    /* The curly brackets are a trick to suppress printing of commands' responses \n    (such as values assigned to a variable etc.) */\n    friendsDF.unpersist()\n    val intraPerc = 100 * intraClassEdgeCount / edgeCount\n    val interPerc = 100 * interClassEdgeCount / edgeCount\n    println(s\"Number of Total Projects: ${edgeCount}\")\n    println(s\"Number of Same-Class Projects: ${intraClassEdgeCount} (${intraPerc}%)\")\n    println(s\"Number of Cross-Class Projects: ${interClassEdgeCount} (${interPerc}%)\")\n}","dateUpdated":"2018-05-14T15:35:18+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":6,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1526312118108_-1461573241","id":"20180312-073136_1079881240","dateCreated":"2018-05-14T15:35:18+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4158"},{"title":"The End","text":"","dateUpdated":"2018-05-14T15:35:18+0000","config":{"tableHide":true,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":6,"editorMode":"ace/mode/scala","editorHide":true,"title":true,"results":{},"enabled":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1526312118108_-1461573241","id":"20180309-124231_422117518","dateCreated":"2018-05-14T15:35:18+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4159"}],"name":"zdenek/HDFS and Oracle Database Data Analysis 1","id":"2DFNPRB1N","angularObjects":{"2DCYNVCR5::2DFNPRB1N":[],"2DEWPP4YM::2DFNPRB1N":[],"2DCT69NKB:shared_process":[],"2DG959HN6::2DFNPRB1N":[],"2DD6JPWJ8::2DFNPRB1N":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}