{"paragraphs":[{"text":"%md\n# Combining data from multiple locations\nIn this demo we'll show how BDM Notebook can be used to work with **data stored in multiple locations** - in this case on the edges.csv file on `hdfs` and the USERS `MySQL` database table. \n\n## About the data\n_Disclaimer: This dataset is completely artificial, it has been generated programatically based on arbitrary input_\n\nThe `USERS` table contains records about the students's name, id, and class category (either `class_0` or `class_1`). Value in the 'category' column depends on which one of the two classes a student attends. \n\nThe `edges.csv` file contains many rows (records). Each row contains two columns. Each column represents a student id. These are the two students' ids that are collaborating on a specific project. \n\nWe use the `USERS` MySQL database table to lookup the names of the student ids and which classes they attended: `class_0` or `class_1`. \n\nWe'll use this dataset to get an idea how frequent such cross-class colaborations are. \n\n\n\n## Required Action\nIn this tutorial, you will add two new paragraphs to beginning of this note. The two paragraphs will add the following DataFrames into spark-context:\n* `graphText` - DataFrame pointing to the CSV file with graph edges (stored on HDFS)\n* `jdbcDF` - DataFrame pointing to the table containing info about individual students (the USERS table in MySQl)\n\nThese DataFrames will be processed by the remaining paragraphs in this Note.","dateUpdated":"2018-05-03T14:39:00+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1525358254400_1103494688","id":"20180309-125713_248006170","dateCreated":"2018-05-03T14:37:34+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2003","user":"anonymous","dateFinished":"2018-05-03T14:39:00+0000","dateStarted":"2018-05-03T14:39:00+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Combining data from multiple locations</h1>\n<p>In this demo we&rsquo;ll show how BDM Notebook can be used to work with <strong>data stored in multiple locations</strong> - in this case on the edges.csv file on <code>hdfs</code> and the USERS <code>MySQL</code> database table. </p>\n<h2>About the data</h2>\n<p><em>Disclaimer: This dataset is completely artificial, it has been generated programatically based on arbitrary input</em></p>\n<p>The <code>USERS</code> table contains records about the students&rsquo;s name, id, and class category (either <code>class_0</code> or <code>class_1</code>). Value in the &lsquo;category&rsquo; column depends on which one of the two classes a student attends. </p>\n<p>The <code>edges.csv</code> file contains many rows (records). Each row contains two columns. Each column represents a student id. These are the two students&rsquo; ids that are collaborating on a specific project. </p>\n<p>We use the <code>USERS</code> MySQL database table to lookup the names of the student ids and which classes they attended: <code>class_0</code> or <code>class_1</code>. </p>\n<p>We&rsquo;ll use this dataset to get an idea how frequent such cross-class colaborations are. </p>\n<h2>Required Action</h2>\n<p>In this tutorial, you will add two new paragraphs to beginning of this note. The two paragraphs will add the following DataFrames into spark-context:<br/>* <code>graphText</code> - DataFrame pointing to the CSV file with graph edges (stored on HDFS)<br/>* <code>jdbcDF</code> - DataFrame pointing to the table containing info about individual students (the USERS table in MySQl)</p>\n<p>These DataFrames will be processed by the remaining paragraphs in this Note.</p>\n</div>"}]}},{"text":"import org.apache.spark.sql.functions.col\n/* \n * Class representing a graph edge - a connection between two users. \n * Each record in the CSV file corresponds to an instance of this class.\n */\ncase class Edge(\n    idStart: Integer,\n    idEnd: Integer\n)\n\n/* Parse the CSV file into a DataFrame consisting of instances of the Edge class */\nval edges = graphText\n    .map(s => s.split(\",\"))\n    .filter(s => s.size == 2)\n    .filter(s => s(0) != \"id\")\n    .map(s => Edge(\n            s(0).toInt,\n            s(1).toInt\n        )\n    )\n    .toDF()\n    .as(\"edges\")\n/* Count the number of student projects (e.g. number of edges in the graph) */\nval edgeCount = edges.count()\n\n/* Assign the loaded MySQL table the alias 'users' for convenience when referencing it's columns. */\nval users = jdbcDF.as(\"users\")\n\n/* Merge the two DataFrames based on user ids. */\nvar friendsDF = edges\n    .join(\n        users, \n        col(\"users.id\") === col(\"edges.idStart\"), \n        \"inner\"\n    )\n    .select(col(\"users.id\"), col(\"users.name\"), col(\"users.category\"), col(\"edges.idEnd\").as(\"friend\"))\n    .as(\"merged\")\n    .join(\n        users, \n        col(\"merged.friend\") === col(\"users.id\"), \n        \"inner\"\n    )\n    .select(\n        col(\"merged.id\"), col(\"merged.name\"), col(\"merged.category\"), \n        col(\"users.id\").as(\"friend_id\"), col(\"users.name\").as(\"friend_name\"), col(\"users.category\").as(\"friend_category\")\n    )\n    .as(\"friends\")\nfriendsDF.persist()\nfriendsDF.registerTempTable(\"FRIENDS\")\n\nval intraClassEdgeCount = friendsDF.where(\"category = friend_category\").count()\nval interClassEdgeCount = friendsDF.where(\"category != friend_category\").count()","dateUpdated":"2018-05-03T14:37:34+0000","config":{"lineNumbers":true,"tableHide":true,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":6,"editorMode":"ace/mode/scala","results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1525358254401_1103109939","id":"20180309-120737_1290905369","dateCreated":"2018-05-03T14:37:34+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:2004"},{"text":"%sql\nselect * from FRIENDS \nwhere \n    category = \"${category=,0(class_0)|1(class_1)}\"","dateUpdated":"2018-05-03T14:37:34+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false},"colWidth":6,"editorMode":"ace/mode/sql","runOnSelectionChange":true,"results":{"0":{"graph":{"mode":"table","height":426,"optionOpen":false}}},"enabled":true},"settings":{"params":{"class 0|class 1,class 0|class 1":"","class_0|class_1,class_0|class_1":"","fields":["1"],"category":"1"},"forms":{"category":{"name":"category","defaultValue":"","options":[{"value":"0","displayName":"class_0","$$hashKey":"object:2195"},{"value":"1","displayName":"class_1","$$hashKey":"object:2196"}],"hidden":false,"$$hashKey":"object:2187"}}},"apps":[],"jobName":"paragraph_1525358254401_1103109939","id":"20180303-105408_426315715","dateCreated":"2018-05-03T14:37:34+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:2005"},{"text":"{\n    /* The curly brackets are a trick to surpress printing of commands' responses \n    (such as values assigned to a variable etc.) */\n    friendsDF.unpersist()\n    val intraPerc = 100 * intraClassEdgeCount / edgeCount\n    val interPerc = 100 * interClassEdgeCount / edgeCount\n    println(s\"Number of projects in total: ${edgeCount}\")\n    println(s\"Number of same-class projetcs: ${intraClassEdgeCount} (${intraPerc}%)\")\n    println(s\"Number of cross-class projetcs: ${interClassEdgeCount} (${interPerc}%)\")\n}","dateUpdated":"2018-05-03T14:37:34+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":6,"editorMode":"ace/mode/scala","results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1525358254402_1104264186","id":"20180312-073136_1079881240","dateCreated":"2018-05-03T14:37:34+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:2006"},{"title":"The End","text":"","dateUpdated":"2018-05-03T14:37:34+0000","config":{"tableHide":true,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":6,"editorMode":"ace/mode/scala","editorHide":true,"title":true,"results":{},"enabled":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1525358254402_1104264186","id":"20180309-124231_422117518","dateCreated":"2018-05-03T14:37:34+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:2007"}],"name":"zdenek/HDFS and MySQL Data Analysis 1","id":"2DCUP1MXN","angularObjects":{"2DB5M8U6Q::2DCUP1MXN":[],"2DE9HKEM7::2DCUP1MXN":[],"2DEAKC15H::2DCUP1MXN":[],"2DBU6M369::2DCUP1MXN":[],"2DDS57CX8::2DCUP1MXN":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}