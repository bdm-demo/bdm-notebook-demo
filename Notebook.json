{"paragraphs":[{"text":"%md\n# Combining data from multiple locations\nIn this tutorial, we'll demonstrate how you can use Oracle Big Data Manager Notebook to work with **data stored in multiple locations** such as the edges.csv file on `hdfs` and the USERS `MySQL` database table. \n\n## About the data\n_Disclaimer: This dataset is completely artificial. It has been generated programatically based on some arbitrary input_\n\nThe `USERS` table contains records about each student name, id, and class category. A value of class_0 in the 'category' column indicates that the student is attending class 0 whereas a value of class_1 indicates that the sudent is attending class 1.  \n\nThe `edges.csv` file contains many rows (records). Each row contains two columns. Each column represents a student id. The two student ids represent two students who are collaborating on a specific class project. \n\nWe use the `USERS` MySQL database table to lookup the names of the student ids and which classes they attended: class_0 or class_1. \n\nWe'll use this dataset to get an idea how frequent such cross-class colaborations are. \n\n\n## Required Action\nIn this tutorial, you will add two new paragraphs to beginning of this note. The two paragraphs will add the following DataFrames into spark-context:\n* `graphText` - DataFrame pointing to the CSV file with graph edges (stored on HDFS)\n* `jdbcDF` - DataFrame pointing to the table containing info about individual students (the USERS table in MySQl)\n\nThese DataFrames will be processed by the remaining paragraphs in this Note.","dateUpdated":"2018-05-07T12:00:42+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1525694442549_-1375842949","id":"20180309-125713_248006170","dateCreated":"2018-05-07T12:00:42+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2805"},{"text":"import org.apache.spark.sql.functions.col\n/* \n * Class representing a graph edge - a connection between two users. \n * Each record in the CSV file corresponds to an instance of this class.\n */\ncase class Edge(\n    idStart: Integer,\n    idEnd: Integer\n)\n\n/* Parse the CSV file into a DataFrame consisting of instances of the Edge class */\nval edges = graphText\n    .map(s => s.split(\",\"))\n    .filter(s => s.size == 2)\n    .filter(s => s(0) != \"id\")\n    .map(s => Edge(\n            s(0).toInt,\n            s(1).toInt\n        )\n    )\n    .toDF()\n    .as(\"edges\")\n/* Count the number of student projects (e.g. number of edges in the graph) */\nval edgeCount = edges.count()\n\n/* Assign the loaded MySQL table the alias 'users' for convenience when referencing it's columns. */\nval users = jdbcDF.as(\"users\")\n\n/* Merge the two DataFrames based on user ids. */\nvar friendsDF = edges\n    .join(\n        users, \n        col(\"users.id\") === col(\"edges.idStart\"), \n        \"inner\"\n    )\n    .select(col(\"users.id\"), col(\"users.name\"), col(\"users.category\"), col(\"edges.idEnd\").as(\"friend\"))\n    .as(\"merged\")\n    .join(\n        users, \n        col(\"merged.friend\") === col(\"users.id\"), \n        \"inner\"\n    )\n    .select(\n        col(\"merged.id\"), col(\"merged.name\"), col(\"merged.category\"), \n        col(\"users.id\").as(\"friend_id\"), col(\"users.name\").as(\"friend_name\"), col(\"users.category\").as(\"friend_category\")\n    )\n    .as(\"friends\")\nfriendsDF.persist()\nfriendsDF.registerTempTable(\"FRIENDS\")\n\nval intraClassEdgeCount = friendsDF.where(\"category = friend_category\").count()\nval interClassEdgeCount = friendsDF.where(\"category != friend_category\").count()","dateUpdated":"2018-05-07T12:00:42+0000","config":{"lineNumbers":true,"tableHide":true,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":6,"editorMode":"ace/mode/scala","results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1525694442549_-1375842949","id":"20180309-120737_1290905369","dateCreated":"2018-05-07T12:00:42+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:2806"},{"title":"Project Collaboration Details","text":"%sql\nselect * from FRIENDS \nwhere \n    category = \"${category=,0(class_0)|1(class_1)}\"","dateUpdated":"2018-05-07T12:01:21+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false},"colWidth":6,"editorMode":"ace/mode/sql","runOnSelectionChange":true,"title":true,"results":{"0":{"graph":{"mode":"table","height":156,"optionOpen":false}}},"enabled":true},"settings":{"params":{"class 0|class 1,class 0|class 1":"","class_0|class_1,class_0|class_1":"","fields":["1"],"category":"1"},"forms":{"category":{"name":"category","defaultValue":"","options":[{"value":"0","displayName":"class_0","$$hashKey":"object:3000"},{"value":"1","displayName":"class_1","$$hashKey":"object:3001"}],"hidden":false,"$$hashKey":"object:2992"}}},"apps":[],"jobName":"paragraph_1525694442550_-1374688702","id":"20180303-105408_426315715","dateCreated":"2018-05-07T12:00:42+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:2807"},{"title":"Project Collaboration Statistics","text":"{\n    /* The curly brackets are a trick to surpress printing of commands' responses \n    (such as values assigned to a variable etc.) */\n    friendsDF.unpersist()\n    val intraPerc = 100 * intraClassEdgeCount / edgeCount\n    val interPerc = 100 * interClassEdgeCount / edgeCount\n    println(s\"Number of projects in total: ${edgeCount}\")\n    println(s\"Number of same-class projetcs: ${intraClassEdgeCount} (${intraPerc}%)\")\n    println(s\"Number of cross-class projetcs: ${interClassEdgeCount} (${interPerc}%)\")\n}","dateUpdated":"2018-05-07T12:01:38+0000","config":{"lineNumbers":true,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":6,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1525694442551_-1375073451","id":"20180312-073136_1079881240","dateCreated":"2018-05-07T12:00:42+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:2808"},{"title":"The End","text":"","dateUpdated":"2018-05-07T12:00:42+0000","config":{"tableHide":true,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":6,"editorMode":"ace/mode/scala","editorHide":true,"title":true,"results":{},"enabled":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1525694442551_-1375073451","id":"20180309-124231_422117518","dateCreated":"2018-05-07T12:00:42+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:2809"}],"name":"HDFS and MySQL Data Analysis","id":"2DE7GR64P","angularObjects":{"2DDS57CX8::2DE7GR64P":[],"2DBU6M369::2DE7GR64P":[],"2DEAKC15H::2DE7GR64P":[],"2DE9HKEM7::2DE7GR64P":[],"2DB5M8U6Q::2DE7GR64P":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}